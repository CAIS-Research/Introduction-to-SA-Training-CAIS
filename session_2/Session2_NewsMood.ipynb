{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SGSuIDP3W2js"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPjBxRjobyPQ06gd/8E39YY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocmello/Introduction-to-SA-Training-CAIS/blob/main/session_2/Session2_NewsMood.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center><img src='https://drive.google.com/uc?id=1FzW9bN0SDepyn5pD-BZIP_9VewVmJWya'></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "xZrTbtEYuGBJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Workshop: **Introduction to Sentiment Analysis: Potentials and limitations**"
      ],
      "metadata": {
        "id": "1SmYAWtOMCGp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "SGSuIDP3W2js"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to install all the packages and requirements\n",
        "!pip install xformers accelerate sentencepiece transformers[sentencepiece]\n",
        "!pip install NRCLex\n",
        "import plotly.express as px\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.expand_frame_repr', False)\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "from nrclex import NRCLex\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "from nltk.sentiment.util import *\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('vader_lexicon')\n",
        "SIA = SentimentIntensityAnalyzer()"
      ],
      "metadata": {
        "id": "6gTgkC2NWXdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Session 2:** Is sentiment in the news becoming more negative over time?\n",
        "\n"
      ],
      "metadata": {
        "id": "erlUcaikskGD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A recent [report](https://reutersinstitute.politics.ox.ac.uk/digital-news-report/2022/dnr-executive-summary) published by the Reuters Institute for the Study of Journalism analysing news consumption across different countries unveiled the increase in news avoidance. Among the reasons, one of the most common answers by interviewees was that ‘news negatively affect their mood’:\n",
        "\n",
        "> 'The proportion of news consumers who say they avoid news, often or sometimes, has increased sharply across countries. This type of selective avoidance has doubled in both Brazil (54%) and the UK (46%) over the last five years, with many respondents saying news has a negative effect on their mood'. (Digital News Report, 2022)\n",
        "\n",
        "<center><img src='https://drive.google.com/uc?id=1rbnFxrJ1rLsMy-cU0yQ78rX2tapW_8g_'></center>\n",
        "\n",
        "However, in other countries like Germany, Sweden, Switzerland, Finland and Netherlands the variation was not considerable.\n",
        "\n",
        "**Question: Is sentiment in the news becoming more negative over time?**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "c11qfjtKsWrp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data: Temporal sentiment analysis of news headlines of BBC articles**"
      ],
      "metadata": {
        "id": "mRwjNbRMr1Kb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data collection:**\n",
        "\n",
        "The data collection consisted of the following steps:\n",
        "\n",
        "1. Getting tweets from @BBCBreaking timeline for specific years (2012,2015,2017,2019 and 2022) using the Twitter API.\n",
        "- Packages used: `Twarc2`\n",
        "2. Filtering the tweets data to get only the url for news articles published by @BBCBreaking.\n",
        "- Packages used: `Pandas`\n",
        "3. From the list of urls, using Newspaper3k to scrape the news headlines from the articles' webpages. After getting the list of news headlines, we removed the duplicated results as @BBCBreaking tweeted some articles more than once.\n",
        "- Packages used: `Newspaper3k` (`Beautiful Soup` & `NLTK`), `Pandas`\n",
        "\n",
        "<br />The image below illustrates the data collection pipeline:\n",
        "\n",
        "<br /><center><img src='https://drive.google.com/uc?id=1kJQGR5cXTEAEJkesCzYbXdvt07bxw24M'></center>\n",
        "\n",
        "<br />**Dataset description:**\n",
        "\n",
        "Dataset is available for download [here](https://zenodo.org/record/6927800)\n",
        "\n",
        "The dataset is in `.csv` format and is organised as follows:\n",
        "\n",
        "    Columns:\n",
        "        ID (tweet ID)\n",
        "        created_at (tweet publication's date)\n",
        "        url (url of the news article attached to the tweet)\n",
        "        Titles (news headline)\n",
        "    Rows: Each row contains a single news article headline sorted by date of publication (created_at).\n",
        "    \n",
        "    Total number of entries: 7213.\n",
        "\n",
        "<br /> **Dataset preview:**\n",
        "<center><img src='https://drive.google.com/uc?id=1ufeRWTM820q8VRA2F2cYuJ38E1BRAZIk'></center>\n",
        "\n",
        "\n",
        "<br /> **Dataset distribution:**\n",
        "<center><img src='https://drive.google.com/uc?id=1z_AI4-IqAyZlM-Wrq72PgL-qJvFYlxxA'></center>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KqVFk-htrv5b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Task: Data Analysis**"
      ],
      "metadata": {
        "id": "Z6JLjrZ8rfBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to import the dataset from Github file and visualise it as DataFrame\n",
        "\n",
        "url = 'https://github.com/caiocmello/Introduction-to-SA-Training-CAIS/blob/main/session_2/BBCBreaking_news.csv?raw=true'\n",
        "df = pd.read_csv(url,index_col=0)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "TmM9XGMD3bNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By running this, the sentiment should be calculated and a label (pos,neu,neg) assigned creating new columns to the DataFrame\n",
        "\n",
        "df['Titles'] = df['Titles'].astype(str) # This will convert column type into string\n",
        "df['Polarity']=df['Titles'].apply(lambda x:SIA.polarity_scores(x)['compound'])\n",
        "df['Neutral']=df['Titles'].apply(lambda x:SIA.polarity_scores(x)['neu'])\n",
        "df['Negative']=df['Titles'].apply(lambda x:SIA.polarity_scores(x)['neg'])\n",
        "df['Positive']=df['Titles'].apply(lambda x:SIA.polarity_scores(x)['pos'])\n",
        "df['Sentiment']=''\n",
        "df.loc[df['Polarity']>0, 'Sentiment']='Positive'\n",
        "df.loc[df['Polarity']==0, 'Sentiment']='Neutral'\n",
        "df.loc[df['Polarity']<0, 'Sentiment']='Negative'"
      ],
      "metadata": {
        "id": "EBwrjOap-eXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this to check if it worked (new columns should appear)\n",
        "\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "cushJYbC_I-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can also filter the data using the following (This way you can see only positive headlines)\n",
        "\n",
        "df.loc[df['Sentiment'] == 'Positive'][:5]"
      ],
      "metadata": {
        "id": "KnoyZeVhACn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to count sentiment score by year and normalise the data\n",
        "\n",
        "df.loc[df['Polarity']>0, 'Sentiment_Score']='2'\n",
        "df.loc[df['Polarity']==0, 'Sentiment_Score']='1'\n",
        "df.loc[df['Polarity']<0, 'Sentiment_Score']='-1'\n",
        "\n",
        "# df[]pd.to_datetime(df.created_at).dt.to_period('m')\n",
        "df[\"month\"] = pd.to_datetime(df.created_at).dt.strftime('%m')\n",
        "df[\"year\"] = pd.to_datetime(df.created_at).dt.strftime('%Y')#%m/%Y\n",
        "df.to_csv('temp.csv',sep=\",\",index=None)\n",
        "\n",
        "df_collection = []\n",
        "for name, group in df.groupby(\"year\"):\n",
        "  df_temp = pd.DataFrame({})\n",
        "  # print(group['Sentiment'].value_counts())\n",
        "  df_da = group['Sentiment'].value_counts().reset_index()\n",
        "  df_da.columns = ['Prefix', 'counts']\n",
        "  df_da[name] =  df_da['counts']*100 / df_da['counts'].sum()\n",
        "  df_collection.append(df_da)\n",
        "  #print(df_da)"
      ],
      "metadata": {
        "id": "ACB5W_BXC09K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# By running this cell, you can visualise the percentage of postive, neutral and negative sentiment outputs for each year\n",
        "\n",
        "df_plotly = pd.concat(df_collection,axis=1).drop(['counts'], axis=1)\n",
        "df_plotly = df_plotly.drop(['Prefix'], axis=1)\n",
        "sentiment_labels = ['Negative', 'Neutral', 'Positive']\n",
        "df_plotly['Label'] = sentiment_labels\n",
        "df_plotly"
      ],
      "metadata": {
        "id": "WVO2A06lGHuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to create a bar chart and visualise the table generated above\n",
        "\n",
        "Negative = [49.674419, 56.338652, 55.396096, 54.907539, 50.276243]\n",
        "Neutral = [35.674419, 31.826241, 30.711825, 31.009957, 25.966851]\n",
        "Positive = [14.651163, 11.835106, 13.892078, 14.082504, 23.756906]\n",
        "index = ['2012', '2015', '2017','2019', '2022']\n",
        "df_vis = pd.DataFrame({'negative': Negative,'neutral': Neutral,'positive': Positive}, index=index)\n",
        "ax = df_vis.plot.bar(rot=0)"
      ],
      "metadata": {
        "id": "x8Rfq6kOHt0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Emotion Analysis**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GS0ojNE2DrMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Emotion detection is a means of identifying distinct human emotion types such as furious, cheerful, or depressed. “Emotion detection,” “affective computing,” “emotion analysis,” and “emotion identification” are all phrases that are sometimes used interchangeably\n",
        "\n",
        "```Nandwani, P., Verma, R. A review on sentiment analysis and emotion detection from text. Soc. Netw. Anal. Min. 11, 81 (2021). https://doi.org/10.1007/s13278-021-00776-6```\n",
        "\n",
        "<br>\n",
        "\n",
        "**The two-dimensional structure of emotions from (Watson and Tellegen, 1985)**\n",
        "\n",
        "<br /><center><img src='https://drive.google.com/uc?id=1nkaOMhySmwfsy-kvBTXsLRU9Q0yUri8r'></center>\n"
      ],
      "metadata": {
        "id": "wpBX7zL4j5be"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['Titles'] = df['Titles'].astype(str)\n",
        "str_titles = ','.join(df['Titles'])\n",
        "text_object = NRCLex(str_titles)\n",
        "text_object.affect_frequencies['fear']\n",
        "text_object.affect_frequencies['anger']\n",
        "text_object.affect_frequencies['anticip']\n",
        "text_object.affect_frequencies['trust']\n",
        "text_object.affect_frequencies['surprise']\n",
        "text_object.affect_frequencies['sadness']\n",
        "text_object.affect_frequencies['disgust']\n",
        "text_object.affect_frequencies['joy']\n",
        "\n",
        "data = text_object.raw_emotion_scores\n",
        "data"
      ],
      "metadata": {
        "id": "QE8xyXr2DweJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_df = pd.DataFrame.from_dict(data, orient='index')\n",
        "emotion_df = emotion_df.reset_index()\n",
        "emotion_df = emotion_df.rename(columns={'index' : 'Emotion Classification' , 0: 'Emotion Count'})\n",
        "emotion_df = emotion_df.sort_values(by=['Emotion Count'], ascending=False)\n",
        "fig = px.bar(emotion_df, x='Emotion Count', y='Emotion Classification', color = 'Emotion Classification', orientation='h',\n",
        "             width = 800, height = 400)\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "FcBSl_jmEtNA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Experimenting with Emotion Analysis**"
      ],
      "metadata": {
        "id": "_KiBnlhnJr7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**List of 28 emotions supported by the [model](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment):**\n",
        "\n",
        "|        |                |             |             |\n",
        "|---------------|----------------|-------------|-------------|\n",
        "| admiration    | amusement      | anger       | annoyance   |\n",
        "| approval      | caring         | confusion   | curiosity   |\n",
        "| desire        | disappointment | disapproval | disgust     |\n",
        "| embarrassment | excitement     | fear        | gratitude   |\n",
        "| grief         | joy            | love        | nervousness |\n",
        "| optimism      | pride          | realization | relief      |\n",
        "| remorse       | sadness        | surprise    | neutral     |"
      ],
      "metadata": {
        "id": "wWDHa86lGneT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **Hands-on: try some sentences to predict emotions**\n",
        "text = \"I hope it works!\" #@param {type:\"string\"}\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
        "model = T5ForConditionalGeneration.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\n",
        "tokenizer = T5Tokenizer.from_pretrained(\"kiri-ai/t5-base-qa-summary-emotion\")\n",
        "\n",
        "def emotion(context):\n",
        "    input_text = f\"emotion: {context}\"\n",
        "    features = tokenizer([input_text], return_tensors='pt')\n",
        "    tokens = model.generate(input_ids=features['input_ids'],\n",
        "            attention_mask=features['attention_mask'], max_length=64)\n",
        "    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "emotion(\"emotion:\" + text + \"</s>\")"
      ],
      "metadata": {
        "id": "5IcIiQ9NEutA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example 1\n",
        "text = \"I love the German bakeries in Sydney. Together with my imported honey it feels like home\" #@param {type:\"string\"}\n",
        "\n",
        "def emotion(context):\n",
        "    input_text = f\"emotion: {context}\"\n",
        "    features = tokenizer([input_text], return_tensors='pt')\n",
        "    tokens = model.generate(input_ids=features['input_ids'],\n",
        "            attention_mask=features['attention_mask'], max_length=64)\n",
        "    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "emotion(\"emotion:\" + text + \"</s>\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kFlasSrPZl9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example 2\n",
        "text = \"OMG! Beyonce's new album was just released!\" #@param {type:\"string\"}\n",
        "\n",
        "def emotion(context):\n",
        "    input_text = f\"emotion: {context}\"\n",
        "    features = tokenizer([input_text], return_tensors='pt')\n",
        "    tokens = model.generate(input_ids=features['input_ids'],\n",
        "            attention_mask=features['attention_mask'], max_length=64)\n",
        "    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "emotion(\"emotion:\" + text + \"</s>\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oK_EPMKmZ-Oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Example 3\n",
        "text = \"The new manager is terrible \" #@param {type:\"string\"}\n",
        "\n",
        "def emotion(context):\n",
        "    input_text = f\"emotion: {context}\"\n",
        "    features = tokenizer([input_text], return_tensors='pt')\n",
        "    tokens = model.generate(input_ids=features['input_ids'],\n",
        "            attention_mask=features['attention_mask'], max_length=64)\n",
        "    return tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
        "\n",
        "emotion(\"emotion:\" + text + \"</s>\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e4TKbgXlb1it"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}