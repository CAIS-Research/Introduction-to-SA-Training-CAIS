{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1HeHWUTFBDln15IbotrfYvIwqHuXipL4P",
      "authorship_tag": "ABX9TyPbQtQVCs4SGrhdjlesXtbk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/caiocmello/Introduction-to-SA-Training-CAIS/blob/main/session_3/Autolabel_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <center><img src='https://drive.google.com/uc?id=1FzW9bN0SDepyn5pD-BZIP_9VewVmJWya'></center>"
      ],
      "metadata": {
        "id": "HtHm-fS3-8b5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Workshop: **Introduction to Sentiment Analysis: Potentials and limitations**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MWeCs07v_DaH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Session 3 Practical**: Sentiment analysis using ChatGPT via the Autolabel library\n",
        "\n",
        "In this notebook, we will explore using *ChatGPT* via the [*Autolabel* Python library](https://github.com/refuel-ai/autolabel) for a sentiment analysis task."
      ],
      "metadata": {
        "id": "yS8UCIs2etnd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prerequisites\n",
        "In order to run the code in this notebook, you need a key for the [*OpenAI* API](https://openai.com/blog/openai-api).\n",
        "\n",
        "**NB**: Using the *OpenAI* API is not free. You will need to set up a payment method to use it. The [costs for using the *OpenAI* API](https://openai.com/pricing) depend on the [model(s)](https://platform.openai.com/docs/models) you use and the amount of [tokens](https://platform.openai.com/tokenizer) in the prompts (input) and responses (output).\n",
        "\n",
        "Notably, [*Autolabel* also supports other Large Language Models (LLMs)](https://docs.refuel.ai/guide/llms/llms/?h=key) besides the ones offered by *OpenAI*. Some of those are available for free, but may be more complicated to set up and possibly also not as performant as the *OpenAI* models (depending on the task as well as the available computing resources).\n",
        "\n",
        "Of course, we also need to install the *Autolabel* library and its dependencies. *Note*: How you need to install and set up *Autolabel* depends on the LLM you want to use (see the [*Autolabel* documentation](https://docs.refuel.ai/) for details)."
      ],
      "metadata": {
        "id": "ILv7GK4lfpIK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install 'refuel-autolabel[openai]'"
      ],
      "metadata": {
        "id": "3w4AabovjLwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Note*: If this cell throws errors or if you cannot execute the following cells, you may have to run this cell again to complete/fix the installation process."
      ],
      "metadata": {
        "id": "b57T5NqhHKFX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup\n",
        "\n",
        "After installing the *Autofuel* library, you need to set your API key.\n",
        "\n",
        "**NB**: Treat your API key like a password and never share it (especially not on *GitHub* or other public locations)! If somebody else has your API key, this can incur costs for you. To increase safety, it is advisable to set a usage limit in your *OpenAI* account (under \"Billing\"). You can also always revoke API keys and generate new ones."
      ],
      "metadata": {
        "id": "9Ev4BRedjvcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# provide your own OpenAI API key here\n",
        "os.environ['OPENAI_API_KEY'] = 'sk-xxxxxxxxxxxxxxxxxxx'"
      ],
      "metadata": {
        "id": "FpXwUROWknG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to set the configuration for the task."
      ],
      "metadata": {
        "id": "nJdeIgnk0nOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    \"task_name\": \"YouTubeCommentSentiment\",\n",
        "    \"task_type\": \"classification\", # classification task\n",
        "    \"model\": {\n",
        "        \"provider\": \"openai\",\n",
        "        \"name\": \"gpt-3.5-turbo\" # the model we want to use\n",
        "    },\n",
        "    \"dataset\": {\n",
        "        \"label_column\": \"label\",\n",
        "        \"delimiter\": \",\"\n",
        "    },\n",
        "    \"prompt\": {\n",
        "        \"task_guidelines\": \"You are an expert at analyzing the sentiment of YouTube comments. Most of the comments are in English, but they may also be in another language. Many of the comments also include emojis. \\nYour job is to classify the provided YouTube comments into one of the following labels: \\n{labels}\",\n",
        "        \"labels\": [\n",
        "            \"positive\",\n",
        "            \"negative\",\n",
        "            \"neutral\",\n",
        "        ],\n",
        "            \"few_shot_examples\": [\n",
        "            {\n",
        "                \"example\": \"This looks awful why Sony why\",\n",
        "                \"label\": \"negative\"\n",
        "            },\n",
        "            {\n",
        "                \"example\": \"It will be an AMAZING MOVIE!!\",\n",
        "                \"label\": \"positive\"\n",
        "            },\n",
        "            {\n",
        "                \"example\": \"Gonna watch the movie just for the meme of it\",\n",
        "                \"label\": \"neutral\"\n",
        "            }\n",
        "        ],\n",
        "        \"few_shot_selection\": \"fixed\",\n",
        "        \"few_shot_num\": 3,\n",
        "        \"example_template\": \"Input: {example}\\nOutput: {label}\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "8FQQXtJj01ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that we are asking the LLM to only use three labels (positive, neutral, negative). We could, e.g., also ask it to provide a sentiment score instead (as has been done in the study by [Rathje et al., 2023](https://osf.io/sekf5))."
      ],
      "metadata": {
        "id": "04lrmKHcNeQ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the classification task\n",
        "\n",
        "In order to run the sentiment analysis classification task, we need to initialize the labeling agent and pass it the configuration we have previously created."
      ],
      "metadata": {
        "id": "HzGPHsJR17v5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create an agent for labeling\n",
        "from autolabel import LabelingAgent\n",
        "\n",
        "agent = LabelingAgent(config, cache=False)"
      ],
      "metadata": {
        "id": "63-oAo2R2L9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will use parts of the data that the examples in the lecture were based on. The file `comments.csv` included in the [*GitHub* repository for the workshop](https://github.com/caiocmello/Introduction-to-SA-Training-CAIS) contains a sample of comments. All of these comments include at least one emoji. To compare the impact of emojis on sentiment classification, the comments in the sample that contain both text and emojis have been duplicated, so that they are included once with and once without emojis. The final test dataset contains 129 comments. You need to download the file from the *GitHub* repo and upload it to your *Google Drive*. Once you have done that, you have to mount your Drive via the \"Files\" menu in *Colab* (i.e., the little folder symbol in the upper-left) and possibly also adjust the file path in the next code cell (*note*: once you have mounted your Drive, you can get the file path by clicking on the three dots next to the file name and selecting \"Copy path\").\n",
        "\n",
        "*Note*: If you want to reduce the costs produced by running the example in this notebook you could, of course, delete rows from the `.csv` file.\n",
        "\n",
        "Before we send our request to the *OpenAI* API, we might want to see an example prompt. This will also provide us with an estimate of how much the request for the full `.csv` file will cost."
      ],
      "metadata": {
        "id": "ln0VQWk6lL8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent.plan('/content/drive/MyDrive/data/comments_test.csv')"
      ],
      "metadata": {
        "id": "bKP_AdIKnbtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we can run the sentiment analysis classification task for the whole dataset.\n",
        "\n",
        "*Note*: Depending on your internet connection and the current *OpenAI* API workload, this may take a bit."
      ],
      "metadata": {
        "id": "0zQsvKgN43il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels, output_df, metrics = agent.run('/content/drive/MyDrive/data/comments_test.csv')"
      ],
      "metadata": {
        "id": "nJRyWOnI49gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now check the results (by printing the first 20 rows from the resulting dataset).\n",
        "\n",
        "*Note*: It may be possible that some comments will not receive a sentiment label."
      ],
      "metadata": {
        "id": "lEFsVA6mGoAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.head(20)"
      ],
      "metadata": {
        "id": "A5ntYton55vO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If everything worked, the resulting `.csv` file should have been stored in the same (*Google Drive*) folder as the input data. The file name should end in `_labeled.csv`.\n",
        "\n",
        "One important final note: The results of text classifications using LLMs should be validated (see [Pangakis et al., 2023](https://arxiv.org/abs/2306.00176)). This is possible in various ways: Through comparisons with results from a) repeated runs using the same LLM, b) other LLMs, c) other automated classification (in our case sentiment analysis) methods, or d) human coders. Validation through comparison with human coders is mostly still considered the gold standard. Notably, however, these approaches can also be combined to, e.g., compute [inter-rater reliability](https://en.wikipedia.org/wiki/Inter-rater_reliability) within and across methods/classification approaches."
      ],
      "metadata": {
        "id": "NPRBnqP8G_Za"
      }
    }
  ]
}